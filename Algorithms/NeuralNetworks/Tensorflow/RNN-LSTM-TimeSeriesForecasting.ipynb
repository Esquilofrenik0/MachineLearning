{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Recurrent Neural Network - Long Short-Term Memory Network for Time Series Forecasting</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 5, 1) (12, 5, 1) (91,) (12,)\n",
      "Epoch 1/350\n",
      "3/3 - 0s - loss: 154569504.0000 - mae: 9612.7705 - val_loss: 208197328.0000 - val_mae: 12177.5322\n",
      "Epoch 2/350\n",
      "3/3 - 0s - loss: 96292136.0000 - mae: 8033.4380 - val_loss: 174714640.0000 - val_mae: 10851.4346\n",
      "Epoch 3/350\n",
      "3/3 - 0s - loss: 53326804.0000 - mae: 5563.1934 - val_loss: 67172504.0000 - val_mae: 6436.9722\n",
      "Epoch 4/350\n",
      "3/3 - 0s - loss: 43485084.0000 - mae: 5068.4795 - val_loss: 71061600.0000 - val_mae: 7152.2700\n",
      "Epoch 5/350\n",
      "3/3 - 0s - loss: 43324068.0000 - mae: 5087.1572 - val_loss: 40307812.0000 - val_mae: 4761.0693\n",
      "Epoch 6/350\n",
      "3/3 - 0s - loss: 26753536.0000 - mae: 3911.8198 - val_loss: 28151482.0000 - val_mae: 4076.8582\n",
      "Epoch 7/350\n",
      "3/3 - 0s - loss: 26099336.0000 - mae: 4042.4724 - val_loss: 40504132.0000 - val_mae: 5213.0171\n",
      "Epoch 8/350\n",
      "3/3 - 0s - loss: 24430058.0000 - mae: 3916.6099 - val_loss: 33938312.0000 - val_mae: 4901.9824\n",
      "Epoch 9/350\n",
      "3/3 - 0s - loss: 17861404.0000 - mae: 3406.1064 - val_loss: 29694090.0000 - val_mae: 4498.4834\n",
      "Epoch 10/350\n",
      "3/3 - 0s - loss: 19448276.0000 - mae: 3598.5583 - val_loss: 24480928.0000 - val_mae: 3982.3965\n",
      "Epoch 11/350\n",
      "3/3 - 0s - loss: 22583244.0000 - mae: 3592.6106 - val_loss: 33300008.0000 - val_mae: 4502.4780\n",
      "Epoch 12/350\n",
      "3/3 - 0s - loss: 16861868.0000 - mae: 3347.7407 - val_loss: 30810560.0000 - val_mae: 4087.5693\n",
      "Epoch 13/350\n",
      "3/3 - 0s - loss: 19276248.0000 - mae: 3403.1147 - val_loss: 23721690.0000 - val_mae: 3670.8613\n",
      "Epoch 14/350\n",
      "3/3 - 0s - loss: 21984858.0000 - mae: 3541.6731 - val_loss: 27320730.0000 - val_mae: 4032.8789\n",
      "Epoch 15/350\n",
      "3/3 - 0s - loss: 24914190.0000 - mae: 3837.5222 - val_loss: 27090034.0000 - val_mae: 4094.8279\n",
      "Epoch 16/350\n",
      "3/3 - 0s - loss: 24377012.0000 - mae: 3766.4746 - val_loss: 25564984.0000 - val_mae: 4063.3757\n",
      "Epoch 17/350\n",
      "3/3 - 0s - loss: 24543728.0000 - mae: 3797.8870 - val_loss: 26020250.0000 - val_mae: 4120.2051\n",
      "Epoch 18/350\n",
      "3/3 - 0s - loss: 24221064.0000 - mae: 3892.4661 - val_loss: 25508562.0000 - val_mae: 3959.2434\n",
      "Epoch 19/350\n",
      "3/3 - 0s - loss: 26145908.0000 - mae: 4133.4082 - val_loss: 26895622.0000 - val_mae: 4007.1067\n",
      "Epoch 20/350\n",
      "3/3 - 0s - loss: 23139178.0000 - mae: 3896.7981 - val_loss: 21602148.0000 - val_mae: 3650.8730\n",
      "Epoch 21/350\n",
      "3/3 - 0s - loss: 21574454.0000 - mae: 3563.3174 - val_loss: 19106380.0000 - val_mae: 3394.6580\n",
      "Epoch 22/350\n",
      "3/3 - 0s - loss: 21887838.0000 - mae: 3485.9170 - val_loss: 22232700.0000 - val_mae: 3816.7361\n",
      "Epoch 23/350\n",
      "3/3 - 0s - loss: 18918842.0000 - mae: 3255.4824 - val_loss: 22699054.0000 - val_mae: 3784.0986\n",
      "Epoch 24/350\n",
      "3/3 - 0s - loss: 18448310.0000 - mae: 3233.0854 - val_loss: 22134474.0000 - val_mae: 3766.4592\n",
      "Epoch 25/350\n",
      "3/3 - 0s - loss: 16316327.0000 - mae: 3012.9805 - val_loss: 17793096.0000 - val_mae: 3600.3420\n",
      "Epoch 26/350\n",
      "3/3 - 0s - loss: 16069771.0000 - mae: 3032.4778 - val_loss: 17868530.0000 - val_mae: 3694.8098\n",
      "Epoch 27/350\n",
      "3/3 - 0s - loss: 17329202.0000 - mae: 3130.2988 - val_loss: 17015722.0000 - val_mae: 3495.1775\n",
      "Epoch 28/350\n",
      "3/3 - 0s - loss: 17016280.0000 - mae: 3037.3667 - val_loss: 17050690.0000 - val_mae: 3482.8496\n",
      "Epoch 29/350\n",
      "3/3 - 0s - loss: 14805497.0000 - mae: 2914.0159 - val_loss: 17152922.0000 - val_mae: 3606.2253\n",
      "Epoch 30/350\n",
      "3/3 - 0s - loss: 14472937.0000 - mae: 2845.3904 - val_loss: 17052312.0000 - val_mae: 3405.8633\n",
      "Epoch 31/350\n",
      "3/3 - 0s - loss: 14115121.0000 - mae: 2814.6023 - val_loss: 16590269.0000 - val_mae: 3308.7815\n",
      "Epoch 32/350\n",
      "3/3 - 0s - loss: 13784295.0000 - mae: 2771.6865 - val_loss: 26728794.0000 - val_mae: 4349.8257\n",
      "Epoch 33/350\n",
      "3/3 - 0s - loss: 14705062.0000 - mae: 2938.2329 - val_loss: 28712118.0000 - val_mae: 4692.7397\n",
      "Epoch 34/350\n",
      "3/3 - 0s - loss: 14755185.0000 - mae: 2941.1340 - val_loss: 21076592.0000 - val_mae: 3849.6902\n",
      "Epoch 35/350\n",
      "3/3 - 0s - loss: 15770255.0000 - mae: 2990.6875 - val_loss: 21601184.0000 - val_mae: 3610.6262\n",
      "Epoch 36/350\n",
      "3/3 - 0s - loss: 15097582.0000 - mae: 2867.1062 - val_loss: 21913262.0000 - val_mae: 4047.0918\n",
      "Epoch 37/350\n",
      "3/3 - 0s - loss: 14069321.0000 - mae: 2901.1326 - val_loss: 23375110.0000 - val_mae: 4349.6694\n",
      "Epoch 38/350\n",
      "3/3 - 0s - loss: 13725657.0000 - mae: 2905.0203 - val_loss: 18361226.0000 - val_mae: 3489.0823\n",
      "Epoch 39/350\n",
      "3/3 - 0s - loss: 15683888.0000 - mae: 2971.2458 - val_loss: 15247855.0000 - val_mae: 2907.3381\n",
      "Epoch 40/350\n",
      "3/3 - 0s - loss: 13334161.0000 - mae: 2778.3425 - val_loss: 17113966.0000 - val_mae: 3512.6018\n",
      "Epoch 41/350\n",
      "3/3 - 0s - loss: 12288149.0000 - mae: 2688.1724 - val_loss: 18745890.0000 - val_mae: 3667.9919\n",
      "Epoch 42/350\n",
      "3/3 - 0s - loss: 11946265.0000 - mae: 2674.8362 - val_loss: 15602667.0000 - val_mae: 3377.7351\n",
      "Epoch 43/350\n",
      "3/3 - 0s - loss: 10677555.0000 - mae: 2466.0889 - val_loss: 14521919.0000 - val_mae: 3192.5508\n",
      "Epoch 44/350\n",
      "3/3 - 0s - loss: 11309531.0000 - mae: 2528.2056 - val_loss: 12370099.0000 - val_mae: 3062.8054\n",
      "Epoch 45/350\n",
      "3/3 - 0s - loss: 11936962.0000 - mae: 2601.4233 - val_loss: 12133957.0000 - val_mae: 3035.9795\n",
      "Epoch 46/350\n",
      "3/3 - 0s - loss: 12023688.0000 - mae: 2594.5100 - val_loss: 13376813.0000 - val_mae: 3207.7363\n",
      "Epoch 47/350\n",
      "3/3 - 0s - loss: 11528864.0000 - mae: 2602.3125 - val_loss: 16425589.0000 - val_mae: 3404.6829\n",
      "Epoch 48/350\n",
      "3/3 - 0s - loss: 12016245.0000 - mae: 2716.0720 - val_loss: 16054785.0000 - val_mae: 3397.7246\n",
      "Epoch 49/350\n",
      "3/3 - 0s - loss: 11172506.0000 - mae: 2612.5374 - val_loss: 17789694.0000 - val_mae: 3753.5330\n",
      "Epoch 50/350\n",
      "3/3 - 0s - loss: 11382256.0000 - mae: 2701.6035 - val_loss: 13112667.0000 - val_mae: 3045.5886\n",
      "Epoch 51/350\n",
      "3/3 - 0s - loss: 11302990.0000 - mae: 2683.4453 - val_loss: 20148562.0000 - val_mae: 3594.9954\n",
      "Epoch 52/350\n",
      "3/3 - 0s - loss: 11813901.0000 - mae: 2682.0947 - val_loss: 21037626.0000 - val_mae: 3789.9600\n",
      "Epoch 53/350\n",
      "3/3 - 0s - loss: 12616978.0000 - mae: 2771.0945 - val_loss: 19893122.0000 - val_mae: 3528.3567\n",
      "Epoch 54/350\n",
      "3/3 - 0s - loss: 13124061.0000 - mae: 2885.0703 - val_loss: 12836963.0000 - val_mae: 2946.6316\n",
      "Epoch 55/350\n",
      "3/3 - 0s - loss: 11532917.0000 - mae: 2687.4702 - val_loss: 13844969.0000 - val_mae: 3086.9148\n",
      "Epoch 56/350\n",
      "3/3 - 0s - loss: 11705050.0000 - mae: 2757.6631 - val_loss: 17086182.0000 - val_mae: 3462.9304\n",
      "Epoch 57/350\n",
      "3/3 - 0s - loss: 11618761.0000 - mae: 2676.8279 - val_loss: 15056832.0000 - val_mae: 3256.1829\n",
      "Epoch 58/350\n",
      "3/3 - 0s - loss: 11241664.0000 - mae: 2669.3147 - val_loss: 14148875.0000 - val_mae: 3234.7419\n",
      "Epoch 59/350\n",
      "3/3 - 0s - loss: 10277119.0000 - mae: 2530.6128 - val_loss: 14837344.0000 - val_mae: 3290.4902\n",
      "Epoch 60/350\n",
      "3/3 - 0s - loss: 10963747.0000 - mae: 2514.8567 - val_loss: 13721000.0000 - val_mae: 3048.0017\n",
      "Epoch 61/350\n",
      "3/3 - 0s - loss: 10260562.0000 - mae: 2480.7493 - val_loss: 17375192.0000 - val_mae: 3612.4482\n",
      "Epoch 62/350\n",
      "3/3 - 0s - loss: 9759058.0000 - mae: 2438.9761 - val_loss: 14498231.0000 - val_mae: 3127.6543\n",
      "Epoch 63/350\n",
      "3/3 - 0s - loss: 10349257.0000 - mae: 2399.5615 - val_loss: 15091759.0000 - val_mae: 2981.0227\n",
      "Epoch 64/350\n",
      "3/3 - 0s - loss: 9764339.0000 - mae: 2288.5117 - val_loss: 17284350.0000 - val_mae: 3699.5706\n",
      "Epoch 65/350\n",
      "3/3 - 0s - loss: 9705195.0000 - mae: 2396.1526 - val_loss: 14160248.0000 - val_mae: 3018.1501\n",
      "Epoch 66/350\n",
      "3/3 - 0s - loss: 8522776.0000 - mae: 2130.7466 - val_loss: 14986096.0000 - val_mae: 2872.6804\n",
      "Epoch 67/350\n",
      "3/3 - 0s - loss: 9413771.0000 - mae: 2226.0234 - val_loss: 14251931.0000 - val_mae: 3050.4893\n",
      "Epoch 68/350\n",
      "3/3 - 0s - loss: 8623074.0000 - mae: 2183.8589 - val_loss: 15897216.0000 - val_mae: 3485.7168\n",
      "Epoch 69/350\n",
      "3/3 - 0s - loss: 9170903.0000 - mae: 2309.6577 - val_loss: 14374267.0000 - val_mae: 3057.3728\n",
      "Epoch 70/350\n",
      "3/3 - 0s - loss: 8997320.0000 - mae: 2255.9819 - val_loss: 14364752.0000 - val_mae: 2833.7312\n",
      "Epoch 71/350\n",
      "3/3 - 0s - loss: 9164100.0000 - mae: 2289.7288 - val_loss: 12322528.0000 - val_mae: 3018.3655\n",
      "Epoch 72/350\n",
      "3/3 - 0s - loss: 9142228.0000 - mae: 2261.8582 - val_loss: 12175088.0000 - val_mae: 2677.5181\n",
      "Epoch 73/350\n",
      "3/3 - 0s - loss: 9277336.0000 - mae: 2231.9338 - val_loss: 12241093.0000 - val_mae: 2586.4666\n",
      "Epoch 74/350\n",
      "3/3 - 0s - loss: 8738674.0000 - mae: 2173.2517 - val_loss: 12466103.0000 - val_mae: 3060.9734\n",
      "Epoch 75/350\n",
      "3/3 - 0s - loss: 8810483.0000 - mae: 2238.0137 - val_loss: 12136419.0000 - val_mae: 2620.9465\n",
      "Epoch 76/350\n",
      "3/3 - 0s - loss: 9854191.0000 - mae: 2297.9905 - val_loss: 12701116.0000 - val_mae: 2594.3250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/350\n",
      "3/3 - 0s - loss: 8605315.0000 - mae: 2236.2212 - val_loss: 13101872.0000 - val_mae: 3247.7227\n",
      "Epoch 78/350\n",
      "3/3 - 0s - loss: 9206102.0000 - mae: 2296.7683 - val_loss: 12137579.0000 - val_mae: 2616.3135\n",
      "Epoch 79/350\n",
      "3/3 - 0s - loss: 9686409.0000 - mae: 2278.3030 - val_loss: 12781605.0000 - val_mae: 2578.1096\n",
      "Epoch 80/350\n",
      "3/3 - 0s - loss: 8875448.0000 - mae: 2221.3655 - val_loss: 12690664.0000 - val_mae: 3145.9485\n",
      "Epoch 81/350\n",
      "3/3 - 0s - loss: 9208749.0000 - mae: 2312.0698 - val_loss: 13291112.0000 - val_mae: 2981.1804\n",
      "Epoch 82/350\n",
      "3/3 - 0s - loss: 9733555.0000 - mae: 2362.3882 - val_loss: 13458944.0000 - val_mae: 3101.8770\n",
      "Epoch 83/350\n",
      "3/3 - 0s - loss: 9962884.0000 - mae: 2450.6477 - val_loss: 12709260.0000 - val_mae: 3102.3474\n",
      "Epoch 84/350\n",
      "3/3 - 0s - loss: 9472178.0000 - mae: 2397.8022 - val_loss: 12258029.0000 - val_mae: 3008.9988\n",
      "Epoch 85/350\n",
      "3/3 - 0s - loss: 9684467.0000 - mae: 2398.7720 - val_loss: 10525048.0000 - val_mae: 2788.6501\n",
      "Epoch 86/350\n",
      "3/3 - 0s - loss: 9529112.0000 - mae: 2493.1899 - val_loss: 10372635.0000 - val_mae: 2754.7019\n",
      "Epoch 87/350\n",
      "3/3 - 0s - loss: 10333084.0000 - mae: 2457.9316 - val_loss: 10769811.0000 - val_mae: 2806.2283\n",
      "Epoch 88/350\n",
      "3/3 - 0s - loss: 9655777.0000 - mae: 2392.2720 - val_loss: 10954883.0000 - val_mae: 2798.4365\n",
      "Epoch 89/350\n",
      "3/3 - 0s - loss: 9870829.0000 - mae: 2373.1084 - val_loss: 10949337.0000 - val_mae: 2762.0286\n",
      "Epoch 90/350\n",
      "3/3 - 0s - loss: 10018924.0000 - mae: 2342.6064 - val_loss: 10356284.0000 - val_mae: 2622.5452\n",
      "Epoch 91/350\n",
      "3/3 - 0s - loss: 9777168.0000 - mae: 2392.3479 - val_loss: 10621882.0000 - val_mae: 2541.1274\n",
      "Epoch 92/350\n",
      "3/3 - 0s - loss: 8776340.0000 - mae: 2185.0066 - val_loss: 10662537.0000 - val_mae: 2529.2188\n",
      "Epoch 93/350\n",
      "3/3 - 0s - loss: 8500456.0000 - mae: 2174.2371 - val_loss: 8418651.0000 - val_mae: 2305.0977\n",
      "Epoch 94/350\n",
      "3/3 - 0s - loss: 8972899.0000 - mae: 2327.7261 - val_loss: 14118891.0000 - val_mae: 3005.8047\n",
      "Epoch 95/350\n",
      "3/3 - 0s - loss: 10822600.0000 - mae: 2417.8359 - val_loss: 14961107.0000 - val_mae: 3037.6960\n",
      "Epoch 96/350\n",
      "3/3 - 0s - loss: 13472046.0000 - mae: 2856.2803 - val_loss: 19049490.0000 - val_mae: 3563.9871\n",
      "Epoch 97/350\n",
      "3/3 - 0s - loss: 14782996.0000 - mae: 3125.6138 - val_loss: 14589739.0000 - val_mae: 3045.4395\n",
      "Epoch 98/350\n",
      "3/3 - 0s - loss: 14713056.0000 - mae: 3081.0244 - val_loss: 20378470.0000 - val_mae: 3481.2383\n",
      "Epoch 99/350\n",
      "3/3 - 0s - loss: 15242479.0000 - mae: 3060.1489 - val_loss: 17915786.0000 - val_mae: 3375.2949\n",
      "Epoch 100/350\n",
      "3/3 - 0s - loss: 12277490.0000 - mae: 2770.4434 - val_loss: 18196826.0000 - val_mae: 3811.8318\n",
      "Epoch 101/350\n",
      "3/3 - 0s - loss: 11700380.0000 - mae: 2719.1890 - val_loss: 15791040.0000 - val_mae: 3148.0371\n",
      "Epoch 102/350\n",
      "3/3 - 0s - loss: 11188183.0000 - mae: 2633.8818 - val_loss: 15285216.0000 - val_mae: 3122.4912\n",
      "Epoch 103/350\n",
      "3/3 - 0s - loss: 10442803.0000 - mae: 2551.6780 - val_loss: 15892228.0000 - val_mae: 3077.8254\n",
      "Epoch 104/350\n",
      "3/3 - 0s - loss: 10956726.0000 - mae: 2514.5222 - val_loss: 14818165.0000 - val_mae: 3064.3525\n",
      "Epoch 105/350\n",
      "3/3 - 0s - loss: 9632622.0000 - mae: 2362.8894 - val_loss: 16123205.0000 - val_mae: 3367.6748\n",
      "Epoch 106/350\n",
      "3/3 - 0s - loss: 9303774.0000 - mae: 2349.8184 - val_loss: 15432085.0000 - val_mae: 3125.2305\n",
      "Epoch 107/350\n",
      "3/3 - 0s - loss: 8886546.0000 - mae: 2313.4316 - val_loss: 13145600.0000 - val_mae: 2944.2405\n",
      "Epoch 108/350\n",
      "3/3 - 0s - loss: 8564023.0000 - mae: 2306.9048 - val_loss: 12844112.0000 - val_mae: 2827.4910\n",
      "Epoch 109/350\n",
      "3/3 - 0s - loss: 7951033.0000 - mae: 2248.9849 - val_loss: 12889651.0000 - val_mae: 2875.4597\n",
      "Epoch 110/350\n",
      "3/3 - 0s - loss: 7849209.0000 - mae: 2252.8176 - val_loss: 13326693.0000 - val_mae: 2765.5381\n",
      "Epoch 111/350\n",
      "3/3 - 0s - loss: 7607885.5000 - mae: 2164.1191 - val_loss: 12959733.0000 - val_mae: 2797.6387\n",
      "Epoch 112/350\n",
      "3/3 - 0s - loss: 7443560.0000 - mae: 2174.9385 - val_loss: 11519223.0000 - val_mae: 2567.3684\n",
      "Epoch 113/350\n",
      "3/3 - 0s - loss: 8761022.0000 - mae: 2330.8052 - val_loss: 10758978.0000 - val_mae: 2432.1301\n",
      "Epoch 114/350\n",
      "3/3 - 0s - loss: 8187184.0000 - mae: 2202.8584 - val_loss: 8314892.0000 - val_mae: 2195.4407\n",
      "Epoch 115/350\n",
      "3/3 - 0s - loss: 7661630.0000 - mae: 2164.8806 - val_loss: 10837863.0000 - val_mae: 2608.4189\n",
      "Epoch 116/350\n",
      "3/3 - 0s - loss: 7635993.5000 - mae: 2146.3418 - val_loss: 12384152.0000 - val_mae: 2791.3000\n",
      "Epoch 117/350\n",
      "3/3 - 0s - loss: 7758680.5000 - mae: 2160.5769 - val_loss: 12545811.0000 - val_mae: 2895.8811\n",
      "Epoch 118/350\n",
      "3/3 - 0s - loss: 8164324.0000 - mae: 2206.6194 - val_loss: 12562840.0000 - val_mae: 2843.0361\n",
      "Epoch 119/350\n",
      "3/3 - 0s - loss: 7934033.5000 - mae: 2116.2837 - val_loss: 12501307.0000 - val_mae: 2902.9348\n",
      "Epoch 120/350\n",
      "3/3 - 0s - loss: 7746475.5000 - mae: 2123.8303 - val_loss: 12493040.0000 - val_mae: 2813.7766\n",
      "Epoch 121/350\n",
      "3/3 - 0s - loss: 8504338.0000 - mae: 2264.5339 - val_loss: 12573608.0000 - val_mae: 2881.4597\n",
      "Epoch 122/350\n",
      "3/3 - 0s - loss: 8015838.0000 - mae: 2086.8994 - val_loss: 13288733.0000 - val_mae: 2868.6179\n",
      "Epoch 123/350\n",
      "3/3 - 0s - loss: 7158744.5000 - mae: 2066.1692 - val_loss: 15102680.0000 - val_mae: 3296.9199\n",
      "Epoch 124/350\n",
      "3/3 - 0s - loss: 7422168.0000 - mae: 2122.2771 - val_loss: 12930553.0000 - val_mae: 2927.2454\n",
      "Epoch 125/350\n",
      "3/3 - 0s - loss: 7469967.5000 - mae: 2037.4349 - val_loss: 11952243.0000 - val_mae: 2899.4873\n",
      "Epoch 126/350\n",
      "3/3 - 0s - loss: 7629495.0000 - mae: 2133.0332 - val_loss: 12786955.0000 - val_mae: 3135.3894\n",
      "Epoch 127/350\n",
      "3/3 - 0s - loss: 8576425.0000 - mae: 2260.2710 - val_loss: 11910859.0000 - val_mae: 2952.2268\n",
      "Epoch 128/350\n",
      "3/3 - 0s - loss: 8039130.5000 - mae: 2212.0730 - val_loss: 13924299.0000 - val_mae: 3237.9941\n",
      "Epoch 129/350\n",
      "3/3 - 0s - loss: 9514527.0000 - mae: 2397.9714 - val_loss: 12767479.0000 - val_mae: 2972.2190\n",
      "Epoch 130/350\n",
      "3/3 - 0s - loss: 8049127.5000 - mae: 2206.7905 - val_loss: 14963899.0000 - val_mae: 3242.0488\n",
      "Epoch 131/350\n",
      "3/3 - 0s - loss: 8953879.0000 - mae: 2357.8184 - val_loss: 12873467.0000 - val_mae: 2925.1826\n",
      "Epoch 132/350\n",
      "3/3 - 0s - loss: 9546319.0000 - mae: 2337.6780 - val_loss: 13006219.0000 - val_mae: 2898.8552\n",
      "Epoch 133/350\n",
      "3/3 - 0s - loss: 8388844.0000 - mae: 2237.5652 - val_loss: 15031837.0000 - val_mae: 3061.8564\n",
      "Epoch 134/350\n",
      "3/3 - 0s - loss: 8664430.0000 - mae: 2347.7280 - val_loss: 14796291.0000 - val_mae: 2948.1702\n",
      "Epoch 135/350\n",
      "3/3 - 0s - loss: 8363384.5000 - mae: 2319.3132 - val_loss: 14610443.0000 - val_mae: 2903.3145\n",
      "Epoch 136/350\n",
      "3/3 - 0s - loss: 8119324.0000 - mae: 2276.8254 - val_loss: 20068780.0000 - val_mae: 3238.5586\n",
      "Epoch 137/350\n",
      "3/3 - 0s - loss: 8053879.5000 - mae: 2281.9148 - val_loss: 19738498.0000 - val_mae: 3410.1492\n",
      "Epoch 138/350\n",
      "3/3 - 0s - loss: 7642145.0000 - mae: 2207.5823 - val_loss: 19646992.0000 - val_mae: 3391.8528\n",
      "Epoch 139/350\n",
      "3/3 - 0s - loss: 7594664.0000 - mae: 2189.5212 - val_loss: 18467730.0000 - val_mae: 3223.8477\n",
      "Epoch 140/350\n",
      "3/3 - 0s - loss: 7146295.0000 - mae: 2111.4373 - val_loss: 18354816.0000 - val_mae: 3176.1172\n",
      "Epoch 141/350\n",
      "3/3 - 0s - loss: 6995700.0000 - mae: 2077.4702 - val_loss: 18422894.0000 - val_mae: 3280.6809\n",
      "Epoch 142/350\n",
      "3/3 - 0s - loss: 7097024.0000 - mae: 2106.7620 - val_loss: 18085206.0000 - val_mae: 3081.3809\n",
      "Epoch 143/350\n",
      "3/3 - 0s - loss: 7279668.0000 - mae: 2099.3967 - val_loss: 18103480.0000 - val_mae: 3114.0559\n",
      "Epoch 144/350\n",
      "3/3 - 0s - loss: 6581924.0000 - mae: 2010.5021 - val_loss: 19661170.0000 - val_mae: 3670.7747\n",
      "Epoch 145/350\n",
      "3/3 - 0s - loss: 7507395.5000 - mae: 2134.0996 - val_loss: 18091976.0000 - val_mae: 3075.3879\n",
      "Epoch 146/350\n",
      "3/3 - 0s - loss: 7827164.0000 - mae: 2111.5779 - val_loss: 14826043.0000 - val_mae: 3144.4336\n",
      "Epoch 147/350\n",
      "3/3 - 0s - loss: 7444346.5000 - mae: 2131.9072 - val_loss: 16622481.0000 - val_mae: 3271.6555\n",
      "Epoch 148/350\n",
      "3/3 - 0s - loss: 6981508.0000 - mae: 2058.6936 - val_loss: 16553091.0000 - val_mae: 3102.6963\n",
      "Epoch 149/350\n",
      "3/3 - 0s - loss: 7450563.0000 - mae: 2075.8806 - val_loss: 16444567.0000 - val_mae: 3239.9812\n",
      "Epoch 150/350\n",
      "3/3 - 0s - loss: 7709735.5000 - mae: 2241.2202 - val_loss: 16023101.0000 - val_mae: 3174.4231\n",
      "Epoch 151/350\n",
      "3/3 - 0s - loss: 7779047.5000 - mae: 2136.8157 - val_loss: 15380967.0000 - val_mae: 3103.0320\n",
      "Epoch 152/350\n",
      "3/3 - 0s - loss: 7360825.5000 - mae: 2054.7769 - val_loss: 15727107.0000 - val_mae: 3228.4192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/350\n",
      "3/3 - 0s - loss: 7639019.0000 - mae: 2120.0037 - val_loss: 16270717.0000 - val_mae: 3125.9763\n",
      "Epoch 154/350\n",
      "3/3 - 0s - loss: 7823756.5000 - mae: 2081.4651 - val_loss: 14881908.0000 - val_mae: 3126.9104\n",
      "Epoch 155/350\n",
      "3/3 - 0s - loss: 7197677.5000 - mae: 2057.4783 - val_loss: 15429920.0000 - val_mae: 3221.3284\n",
      "Epoch 156/350\n",
      "3/3 - 0s - loss: 7032444.5000 - mae: 2068.5186 - val_loss: 14602495.0000 - val_mae: 3120.8164\n",
      "Epoch 157/350\n",
      "3/3 - 0s - loss: 7621417.5000 - mae: 2163.1509 - val_loss: 13188029.0000 - val_mae: 3080.7078\n",
      "Epoch 158/350\n",
      "3/3 - 0s - loss: 7935989.5000 - mae: 2263.2705 - val_loss: 12365429.0000 - val_mae: 3021.9734\n",
      "Epoch 159/350\n",
      "3/3 - 0s - loss: 9078743.0000 - mae: 2433.1628 - val_loss: 12150805.0000 - val_mae: 3002.9329\n",
      "Epoch 160/350\n",
      "3/3 - 0s - loss: 9083552.0000 - mae: 2453.2349 - val_loss: 11634451.0000 - val_mae: 2917.5012\n",
      "Epoch 161/350\n",
      "3/3 - 0s - loss: 9339412.0000 - mae: 2465.7104 - val_loss: 11222296.0000 - val_mae: 2877.3457\n",
      "Epoch 162/350\n",
      "3/3 - 0s - loss: 9027148.0000 - mae: 2385.1418 - val_loss: 10443785.0000 - val_mae: 2560.3118\n",
      "Epoch 163/350\n",
      "3/3 - 0s - loss: 8515071.0000 - mae: 2295.0596 - val_loss: 10180075.0000 - val_mae: 2574.6841\n",
      "Epoch 164/350\n",
      "3/3 - 0s - loss: 8067940.0000 - mae: 2220.6809 - val_loss: 10342116.0000 - val_mae: 2553.8625\n",
      "Epoch 165/350\n",
      "3/3 - 0s - loss: 7982092.5000 - mae: 2213.4482 - val_loss: 11500795.0000 - val_mae: 2769.5378\n",
      "Epoch 166/350\n",
      "3/3 - 0s - loss: 8073660.5000 - mae: 2171.3857 - val_loss: 11854984.0000 - val_mae: 2785.0254\n",
      "Epoch 167/350\n",
      "3/3 - 0s - loss: 7599051.5000 - mae: 2116.7998 - val_loss: 14302653.0000 - val_mae: 2927.0789\n",
      "Epoch 168/350\n",
      "3/3 - 0s - loss: 7741804.5000 - mae: 2147.5288 - val_loss: 14699377.0000 - val_mae: 2952.2502\n",
      "Epoch 169/350\n",
      "3/3 - 0s - loss: 7369471.5000 - mae: 2082.4944 - val_loss: 14097543.0000 - val_mae: 2896.4910\n",
      "Epoch 170/350\n",
      "3/3 - 0s - loss: 8029241.5000 - mae: 2155.8855 - val_loss: 14402061.0000 - val_mae: 2914.4990\n",
      "Epoch 171/350\n",
      "3/3 - 0s - loss: 7312406.0000 - mae: 2054.6875 - val_loss: 13786312.0000 - val_mae: 2870.9636\n",
      "Epoch 172/350\n",
      "3/3 - 0s - loss: 7967597.5000 - mae: 2253.1912 - val_loss: 14833707.0000 - val_mae: 2980.3210\n",
      "Epoch 173/350\n",
      "3/3 - 0s - loss: 8106937.0000 - mae: 2121.3220 - val_loss: 13016332.0000 - val_mae: 2721.3613\n",
      "Epoch 174/350\n",
      "3/3 - 0s - loss: 8374431.5000 - mae: 2274.4148 - val_loss: 12921943.0000 - val_mae: 2723.6787\n",
      "Epoch 175/350\n",
      "3/3 - 0s - loss: 7320936.0000 - mae: 2037.4587 - val_loss: 15716768.0000 - val_mae: 3115.5168\n",
      "Epoch 176/350\n",
      "3/3 - 0s - loss: 7891903.5000 - mae: 2099.5432 - val_loss: 12980533.0000 - val_mae: 2847.1609\n",
      "Epoch 177/350\n",
      "3/3 - 0s - loss: 7588506.5000 - mae: 2201.2156 - val_loss: 11554789.0000 - val_mae: 2568.7546\n",
      "Epoch 178/350\n",
      "3/3 - 0s - loss: 7383135.5000 - mae: 2069.9226 - val_loss: 12427045.0000 - val_mae: 2695.8105\n",
      "Epoch 179/350\n",
      "3/3 - 0s - loss: 7100819.5000 - mae: 2098.1584 - val_loss: 12243347.0000 - val_mae: 2735.5635\n",
      "Epoch 180/350\n",
      "3/3 - 0s - loss: 7090693.5000 - mae: 2071.4128 - val_loss: 12360591.0000 - val_mae: 2727.3787\n",
      "Epoch 181/350\n",
      "3/3 - 0s - loss: 6701949.0000 - mae: 2009.9375 - val_loss: 12325397.0000 - val_mae: 2779.7031\n",
      "Epoch 182/350\n",
      "3/3 - 0s - loss: 6869374.5000 - mae: 2053.0247 - val_loss: 12146784.0000 - val_mae: 2752.4944\n",
      "Epoch 183/350\n",
      "3/3 - 0s - loss: 7352937.5000 - mae: 2000.5565 - val_loss: 13111248.0000 - val_mae: 2876.4841\n",
      "Epoch 184/350\n",
      "3/3 - 0s - loss: 6616901.5000 - mae: 2028.2784 - val_loss: 13370240.0000 - val_mae: 3033.6780\n",
      "Epoch 185/350\n",
      "3/3 - 0s - loss: 6930269.0000 - mae: 2137.8494 - val_loss: 12317627.0000 - val_mae: 2811.5164\n",
      "Epoch 186/350\n",
      "3/3 - 0s - loss: 7294067.5000 - mae: 1965.2657 - val_loss: 11476153.0000 - val_mae: 2612.1194\n",
      "Epoch 187/350\n",
      "3/3 - 0s - loss: 6949647.5000 - mae: 2063.4800 - val_loss: 12077661.0000 - val_mae: 2860.1377\n",
      "Epoch 188/350\n",
      "3/3 - 0s - loss: 7414931.0000 - mae: 2070.7888 - val_loss: 12467283.0000 - val_mae: 2787.0137\n",
      "Epoch 189/350\n",
      "3/3 - 0s - loss: 7448096.5000 - mae: 2086.4309 - val_loss: 12302432.0000 - val_mae: 2950.0898\n",
      "Epoch 190/350\n",
      "3/3 - 0s - loss: 6773878.0000 - mae: 2008.3151 - val_loss: 12209587.0000 - val_mae: 2710.4358\n",
      "Epoch 191/350\n",
      "3/3 - 0s - loss: 6846974.0000 - mae: 1902.7365 - val_loss: 11722403.0000 - val_mae: 2845.1035\n",
      "Epoch 192/350\n",
      "3/3 - 0s - loss: 6902176.5000 - mae: 1980.5752 - val_loss: 11706605.0000 - val_mae: 2787.3074\n",
      "Epoch 193/350\n",
      "3/3 - 0s - loss: 6905958.5000 - mae: 1975.6254 - val_loss: 11718128.0000 - val_mae: 2764.4961\n",
      "Epoch 194/350\n",
      "3/3 - 0s - loss: 6961475.5000 - mae: 2018.1802 - val_loss: 11918992.0000 - val_mae: 2822.8918\n",
      "Epoch 195/350\n",
      "3/3 - 0s - loss: 6739290.5000 - mae: 1877.3074 - val_loss: 12256475.0000 - val_mae: 2816.9851\n",
      "Epoch 196/350\n",
      "3/3 - 0s - loss: 6371698.0000 - mae: 1860.8729 - val_loss: 14741512.0000 - val_mae: 3267.0286\n",
      "Epoch 197/350\n",
      "3/3 - 0s - loss: 7141097.0000 - mae: 2093.7458 - val_loss: 12792191.0000 - val_mae: 2870.1396\n",
      "Epoch 198/350\n",
      "3/3 - 0s - loss: 7319439.5000 - mae: 1947.6118 - val_loss: 13180547.0000 - val_mae: 3047.4680\n",
      "Epoch 199/350\n",
      "3/3 - 0s - loss: 6827183.0000 - mae: 2017.9125 - val_loss: 13187188.0000 - val_mae: 3088.6836\n",
      "Epoch 200/350\n",
      "3/3 - 0s - loss: 6064307.5000 - mae: 1869.6681 - val_loss: 12394175.0000 - val_mae: 2779.0195\n",
      "Epoch 201/350\n",
      "3/3 - 0s - loss: 6963236.0000 - mae: 1902.1365 - val_loss: 13179551.0000 - val_mae: 3076.4463\n",
      "Epoch 202/350\n",
      "3/3 - 0s - loss: 6775515.5000 - mae: 2017.4047 - val_loss: 12625496.0000 - val_mae: 2929.4143\n",
      "Epoch 203/350\n",
      "3/3 - 0s - loss: 6005063.5000 - mae: 1807.4274 - val_loss: 12092613.0000 - val_mae: 2742.2695\n",
      "Epoch 204/350\n",
      "3/3 - 0s - loss: 6342827.5000 - mae: 1879.6085 - val_loss: 12336349.0000 - val_mae: 2923.4622\n",
      "Epoch 205/350\n",
      "3/3 - 0s - loss: 6037847.0000 - mae: 1820.0668 - val_loss: 11747541.0000 - val_mae: 2747.0940\n",
      "Epoch 206/350\n",
      "3/3 - 0s - loss: 6082406.5000 - mae: 1795.5599 - val_loss: 12231913.0000 - val_mae: 2919.4524\n",
      "Epoch 207/350\n",
      "3/3 - 0s - loss: 6291290.0000 - mae: 1926.8409 - val_loss: 12136796.0000 - val_mae: 2871.2034\n",
      "Epoch 208/350\n",
      "3/3 - 0s - loss: 6480311.0000 - mae: 1809.8983 - val_loss: 12387872.0000 - val_mae: 2784.7839\n",
      "Epoch 209/350\n",
      "3/3 - 0s - loss: 6537543.0000 - mae: 1905.8969 - val_loss: 14536229.0000 - val_mae: 3251.2441\n",
      "Epoch 210/350\n",
      "3/3 - 0s - loss: 6191758.0000 - mae: 1874.2399 - val_loss: 11999765.0000 - val_mae: 2657.6367\n",
      "Epoch 211/350\n",
      "3/3 - 0s - loss: 6477659.5000 - mae: 1842.4368 - val_loss: 12036652.0000 - val_mae: 2923.5149\n",
      "Epoch 212/350\n",
      "3/3 - 0s - loss: 6099160.0000 - mae: 1842.7803 - val_loss: 11424699.0000 - val_mae: 2703.5215\n",
      "Epoch 213/350\n",
      "3/3 - 0s - loss: 5898199.0000 - mae: 1764.7192 - val_loss: 11600792.0000 - val_mae: 2788.1631\n",
      "Epoch 214/350\n",
      "3/3 - 0s - loss: 6012356.0000 - mae: 1822.6710 - val_loss: 11901561.0000 - val_mae: 2821.9336\n",
      "Epoch 215/350\n",
      "3/3 - 0s - loss: 5895345.0000 - mae: 1791.0050 - val_loss: 11965688.0000 - val_mae: 2787.4539\n",
      "Epoch 216/350\n",
      "3/3 - 0s - loss: 5863659.5000 - mae: 1768.5919 - val_loss: 12895475.0000 - val_mae: 3061.0496\n",
      "Epoch 217/350\n",
      "3/3 - 0s - loss: 5824234.0000 - mae: 1789.6432 - val_loss: 11781736.0000 - val_mae: 2766.2195\n",
      "Epoch 218/350\n",
      "3/3 - 0s - loss: 6177958.0000 - mae: 1803.1820 - val_loss: 12164464.0000 - val_mae: 2930.7070\n",
      "Epoch 219/350\n",
      "3/3 - 0s - loss: 6052751.0000 - mae: 1860.2919 - val_loss: 12599036.0000 - val_mae: 3024.1406\n",
      "Epoch 220/350\n",
      "3/3 - 0s - loss: 6203967.5000 - mae: 1825.0887 - val_loss: 11617479.0000 - val_mae: 2702.9304\n",
      "Epoch 221/350\n",
      "3/3 - 0s - loss: 5678739.0000 - mae: 1739.1161 - val_loss: 12946797.0000 - val_mae: 3079.3235\n",
      "Epoch 222/350\n",
      "3/3 - 0s - loss: 6040298.0000 - mae: 1882.0845 - val_loss: 11185368.0000 - val_mae: 2650.1858\n",
      "Epoch 223/350\n",
      "3/3 - 0s - loss: 5884240.0000 - mae: 1755.9452 - val_loss: 11297675.0000 - val_mae: 2696.7402\n",
      "Epoch 224/350\n",
      "3/3 - 0s - loss: 5769348.0000 - mae: 1733.2560 - val_loss: 11939599.0000 - val_mae: 2889.4189\n",
      "Epoch 225/350\n",
      "3/3 - 0s - loss: 5666303.5000 - mae: 1745.4760 - val_loss: 11756231.0000 - val_mae: 2773.3730\n",
      "Epoch 226/350\n",
      "3/3 - 0s - loss: 5747145.5000 - mae: 1739.4738 - val_loss: 12465415.0000 - val_mae: 2971.5645\n",
      "Epoch 227/350\n",
      "3/3 - 0s - loss: 5827501.5000 - mae: 1801.7632 - val_loss: 12038901.0000 - val_mae: 2918.9021\n",
      "Epoch 228/350\n",
      "3/3 - 0s - loss: 7126662.5000 - mae: 1928.8876 - val_loss: 11597520.0000 - val_mae: 2789.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/350\n",
      "3/3 - 0s - loss: 6696320.0000 - mae: 2004.3048 - val_loss: 13666155.0000 - val_mae: 3152.2200\n",
      "Epoch 230/350\n",
      "3/3 - 0s - loss: 5906729.0000 - mae: 1823.5994 - val_loss: 11487995.0000 - val_mae: 2619.3530\n",
      "Epoch 231/350\n",
      "3/3 - 0s - loss: 5987550.0000 - mae: 1777.6610 - val_loss: 12466645.0000 - val_mae: 2988.6550\n",
      "Epoch 232/350\n",
      "3/3 - 0s - loss: 5975095.0000 - mae: 1861.7766 - val_loss: 11832307.0000 - val_mae: 2879.7102\n",
      "Epoch 233/350\n",
      "3/3 - 0s - loss: 6368856.0000 - mae: 1867.1926 - val_loss: 11504707.0000 - val_mae: 2727.0107\n",
      "Epoch 234/350\n",
      "3/3 - 0s - loss: 5889360.5000 - mae: 1801.6903 - val_loss: 13491887.0000 - val_mae: 3152.2678\n",
      "Epoch 235/350\n",
      "3/3 - 0s - loss: 5749063.5000 - mae: 1780.5363 - val_loss: 11596261.0000 - val_mae: 2687.8193\n",
      "Epoch 236/350\n",
      "3/3 - 0s - loss: 6026052.0000 - mae: 1800.5432 - val_loss: 13196848.0000 - val_mae: 3123.8252\n",
      "Epoch 237/350\n",
      "3/3 - 0s - loss: 6774576.5000 - mae: 2019.3573 - val_loss: 11651397.0000 - val_mae: 2835.7883\n",
      "Epoch 238/350\n",
      "3/3 - 0s - loss: 6221349.5000 - mae: 1789.2991 - val_loss: 11263979.0000 - val_mae: 2674.0017\n",
      "Epoch 239/350\n",
      "3/3 - 0s - loss: 5898560.0000 - mae: 1755.8219 - val_loss: 14218128.0000 - val_mae: 3207.9697\n",
      "Epoch 240/350\n",
      "3/3 - 0s - loss: 6472271.0000 - mae: 1889.7706 - val_loss: 11243693.0000 - val_mae: 2635.2830\n",
      "Epoch 241/350\n",
      "3/3 - 0s - loss: 6052942.0000 - mae: 1811.8458 - val_loss: 12205007.0000 - val_mae: 2980.1609\n",
      "Epoch 242/350\n",
      "3/3 - 0s - loss: 5636380.0000 - mae: 1761.6790 - val_loss: 10661743.0000 - val_mae: 2558.4294\n",
      "Epoch 243/350\n",
      "3/3 - 0s - loss: 6095714.5000 - mae: 1769.1361 - val_loss: 11066423.0000 - val_mae: 2725.0537\n",
      "Epoch 244/350\n",
      "3/3 - 0s - loss: 5768657.0000 - mae: 1738.0985 - val_loss: 12131400.0000 - val_mae: 2936.5410\n",
      "Epoch 245/350\n",
      "3/3 - 0s - loss: 6203234.5000 - mae: 1882.6885 - val_loss: 12500148.0000 - val_mae: 2986.1594\n",
      "Epoch 246/350\n",
      "3/3 - 0s - loss: 5628588.5000 - mae: 1730.0511 - val_loss: 11736285.0000 - val_mae: 2748.8591\n",
      "Epoch 247/350\n",
      "3/3 - 0s - loss: 5631884.5000 - mae: 1736.9044 - val_loss: 13470612.0000 - val_mae: 3137.1514\n",
      "Epoch 248/350\n",
      "3/3 - 0s - loss: 5641263.0000 - mae: 1771.5994 - val_loss: 11460645.0000 - val_mae: 2714.2842\n",
      "Epoch 249/350\n",
      "3/3 - 0s - loss: 5930810.5000 - mae: 1775.3099 - val_loss: 11443133.0000 - val_mae: 2761.5979\n",
      "Epoch 250/350\n",
      "3/3 - 0s - loss: 5654159.5000 - mae: 1747.6871 - val_loss: 13188408.0000 - val_mae: 3059.6250\n",
      "Epoch 251/350\n",
      "3/3 - 0s - loss: 5380032.0000 - mae: 1754.4764 - val_loss: 11131304.0000 - val_mae: 2586.5510\n",
      "Epoch 252/350\n",
      "3/3 - 0s - loss: 5988027.0000 - mae: 1755.5062 - val_loss: 11616747.0000 - val_mae: 2820.2966\n",
      "Epoch 253/350\n",
      "3/3 - 0s - loss: 5538936.5000 - mae: 1717.1006 - val_loss: 12008800.0000 - val_mae: 2900.2385\n",
      "Epoch 254/350\n",
      "3/3 - 0s - loss: 5540527.5000 - mae: 1733.9856 - val_loss: 12042621.0000 - val_mae: 2899.5930\n",
      "Epoch 255/350\n",
      "3/3 - 0s - loss: 5635918.0000 - mae: 1703.5175 - val_loss: 11632488.0000 - val_mae: 2820.0359\n",
      "Epoch 256/350\n",
      "3/3 - 0s - loss: 5576225.5000 - mae: 1697.5083 - val_loss: 12276837.0000 - val_mae: 2952.6633\n",
      "Epoch 257/350\n",
      "3/3 - 0s - loss: 5410667.0000 - mae: 1682.4697 - val_loss: 11060698.0000 - val_mae: 2618.3044\n",
      "Epoch 258/350\n",
      "3/3 - 0s - loss: 5428074.5000 - mae: 1692.5233 - val_loss: 12694712.0000 - val_mae: 3012.7988\n",
      "Epoch 259/350\n",
      "3/3 - 0s - loss: 5578327.0000 - mae: 1726.8907 - val_loss: 11469301.0000 - val_mae: 2777.8054\n",
      "Epoch 260/350\n",
      "3/3 - 0s - loss: 5422526.0000 - mae: 1684.1479 - val_loss: 11657763.0000 - val_mae: 2853.3262\n",
      "Epoch 261/350\n",
      "3/3 - 0s - loss: 5867309.0000 - mae: 1821.3798 - val_loss: 11290523.0000 - val_mae: 2764.4875\n",
      "Epoch 262/350\n",
      "3/3 - 0s - loss: 5525278.0000 - mae: 1731.6942 - val_loss: 10758018.0000 - val_mae: 2583.4221\n",
      "Epoch 263/350\n",
      "3/3 - 0s - loss: 5370324.0000 - mae: 1679.1448 - val_loss: 12465933.0000 - val_mae: 2977.5283\n",
      "Epoch 264/350\n",
      "3/3 - 0s - loss: 5268107.5000 - mae: 1688.5376 - val_loss: 11597931.0000 - val_mae: 2771.0442\n",
      "Epoch 265/350\n",
      "3/3 - 0s - loss: 5419594.0000 - mae: 1692.0820 - val_loss: 12013819.0000 - val_mae: 2874.0505\n",
      "Epoch 266/350\n",
      "3/3 - 0s - loss: 5335650.0000 - mae: 1689.7163 - val_loss: 11845075.0000 - val_mae: 2845.0857\n",
      "Epoch 267/350\n",
      "3/3 - 0s - loss: 5725644.0000 - mae: 1797.0505 - val_loss: 11429689.0000 - val_mae: 2763.0381\n",
      "Epoch 268/350\n",
      "3/3 - 0s - loss: 5161685.0000 - mae: 1634.0369 - val_loss: 11019171.0000 - val_mae: 2576.6055\n",
      "Epoch 269/350\n",
      "3/3 - 0s - loss: 5517851.5000 - mae: 1727.5117 - val_loss: 12483003.0000 - val_mae: 2976.5530\n",
      "Epoch 270/350\n",
      "3/3 - 0s - loss: 5530361.0000 - mae: 1758.6384 - val_loss: 11560515.0000 - val_mae: 2811.2473\n",
      "Epoch 271/350\n",
      "3/3 - 0s - loss: 5178650.5000 - mae: 1650.0635 - val_loss: 10975689.0000 - val_mae: 2626.4285\n",
      "Epoch 272/350\n",
      "3/3 - 0s - loss: 5297207.0000 - mae: 1689.9797 - val_loss: 12422307.0000 - val_mae: 2964.4639\n",
      "Epoch 273/350\n",
      "3/3 - 0s - loss: 5419486.0000 - mae: 1732.1968 - val_loss: 11304045.0000 - val_mae: 2739.7539\n",
      "Epoch 274/350\n",
      "3/3 - 0s - loss: 5553287.5000 - mae: 1713.0582 - val_loss: 11648576.0000 - val_mae: 2813.5010\n",
      "Epoch 275/350\n",
      "3/3 - 0s - loss: 5193199.5000 - mae: 1670.2479 - val_loss: 12677228.0000 - val_mae: 2987.2297\n",
      "Epoch 276/350\n",
      "3/3 - 0s - loss: 5202114.0000 - mae: 1666.2234 - val_loss: 11276735.0000 - val_mae: 2694.7471\n",
      "Epoch 277/350\n",
      "3/3 - 0s - loss: 5396655.0000 - mae: 1692.0094 - val_loss: 11960445.0000 - val_mae: 2895.1160\n",
      "Epoch 278/350\n",
      "3/3 - 0s - loss: 5365215.0000 - mae: 1690.7339 - val_loss: 11863629.0000 - val_mae: 2871.7957\n",
      "Epoch 279/350\n",
      "3/3 - 0s - loss: 6083900.5000 - mae: 1894.9724 - val_loss: 11224676.0000 - val_mae: 2723.0430\n",
      "Epoch 280/350\n",
      "3/3 - 0s - loss: 6068956.0000 - mae: 1817.8381 - val_loss: 10774816.0000 - val_mae: 2594.2810\n",
      "Epoch 281/350\n",
      "3/3 - 0s - loss: 5995584.5000 - mae: 1833.1144 - val_loss: 13187867.0000 - val_mae: 3007.6272\n",
      "Epoch 282/350\n",
      "3/3 - 0s - loss: 6763455.5000 - mae: 1912.6882 - val_loss: 11112285.0000 - val_mae: 2641.0010\n",
      "Epoch 283/350\n",
      "3/3 - 0s - loss: 6084649.5000 - mae: 1909.7441 - val_loss: 13711851.0000 - val_mae: 3109.2097\n",
      "Epoch 284/350\n",
      "3/3 - 0s - loss: 5373051.0000 - mae: 1721.7310 - val_loss: 10953098.0000 - val_mae: 2567.2952\n",
      "Epoch 285/350\n",
      "3/3 - 0s - loss: 5353002.5000 - mae: 1646.0024 - val_loss: 13767732.0000 - val_mae: 3111.7129\n",
      "Epoch 286/350\n",
      "3/3 - 0s - loss: 5676103.5000 - mae: 1842.0114 - val_loss: 10790483.0000 - val_mae: 2601.9324\n",
      "Epoch 287/350\n",
      "3/3 - 0s - loss: 5508732.0000 - mae: 1718.7902 - val_loss: 11202828.0000 - val_mae: 2717.5405\n",
      "Epoch 288/350\n",
      "3/3 - 0s - loss: 5241917.0000 - mae: 1652.3455 - val_loss: 11821693.0000 - val_mae: 2846.2258\n",
      "Epoch 289/350\n",
      "3/3 - 0s - loss: 5312404.5000 - mae: 1692.3176 - val_loss: 11597264.0000 - val_mae: 2788.8953\n",
      "Epoch 290/350\n",
      "3/3 - 0s - loss: 5166950.5000 - mae: 1665.4269 - val_loss: 11798036.0000 - val_mae: 2841.3372\n",
      "Epoch 291/350\n",
      "3/3 - 0s - loss: 5033904.0000 - mae: 1614.5710 - val_loss: 10987184.0000 - val_mae: 2656.5227\n",
      "Epoch 292/350\n",
      "3/3 - 0s - loss: 5176440.0000 - mae: 1670.9540 - val_loss: 11810215.0000 - val_mae: 2848.6711\n",
      "Epoch 293/350\n",
      "3/3 - 0s - loss: 5123378.5000 - mae: 1635.5907 - val_loss: 10768148.0000 - val_mae: 2603.9766\n",
      "Epoch 294/350\n",
      "3/3 - 0s - loss: 5208650.0000 - mae: 1647.5615 - val_loss: 10787561.0000 - val_mae: 2604.0107\n",
      "Epoch 295/350\n",
      "3/3 - 0s - loss: 5100454.0000 - mae: 1638.1351 - val_loss: 11678393.0000 - val_mae: 2802.4963\n",
      "Epoch 296/350\n",
      "3/3 - 0s - loss: 5036708.0000 - mae: 1634.9760 - val_loss: 11957456.0000 - val_mae: 2856.2500\n",
      "Epoch 297/350\n",
      "3/3 - 0s - loss: 5062059.5000 - mae: 1632.8517 - val_loss: 11156845.0000 - val_mae: 2695.1091\n",
      "Epoch 298/350\n",
      "3/3 - 0s - loss: 5016407.5000 - mae: 1618.7661 - val_loss: 11532452.0000 - val_mae: 2787.7898\n",
      "Epoch 299/350\n",
      "3/3 - 0s - loss: 4994899.0000 - mae: 1609.6173 - val_loss: 10973028.0000 - val_mae: 2662.0012\n",
      "Epoch 300/350\n",
      "3/3 - 0s - loss: 5000340.5000 - mae: 1614.1545 - val_loss: 11766979.0000 - val_mae: 2842.4922\n",
      "Epoch 301/350\n",
      "3/3 - 0s - loss: 4999823.5000 - mae: 1611.9138 - val_loss: 10927377.0000 - val_mae: 2683.5432\n",
      "Epoch 302/350\n",
      "3/3 - 0s - loss: 4964015.5000 - mae: 1596.1743 - val_loss: 11277712.0000 - val_mae: 2735.1035\n",
      "Epoch 303/350\n",
      "3/3 - 0s - loss: 4974649.5000 - mae: 1611.0369 - val_loss: 11303699.0000 - val_mae: 2726.9314\n",
      "Epoch 304/350\n",
      "3/3 - 0s - loss: 4999926.0000 - mae: 1619.8771 - val_loss: 11664645.0000 - val_mae: 2800.1140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/350\n",
      "3/3 - 0s - loss: 4938700.5000 - mae: 1632.1355 - val_loss: 11544347.0000 - val_mae: 2770.9001\n",
      "Epoch 306/350\n",
      "3/3 - 0s - loss: 4910919.0000 - mae: 1596.0979 - val_loss: 10739567.0000 - val_mae: 2603.2498\n",
      "Epoch 307/350\n",
      "3/3 - 0s - loss: 4896588.5000 - mae: 1600.6567 - val_loss: 12003653.0000 - val_mae: 2854.7344\n",
      "Epoch 308/350\n",
      "3/3 - 0s - loss: 4994530.0000 - mae: 1628.9642 - val_loss: 11278992.0000 - val_mae: 2731.9343\n",
      "Epoch 309/350\n",
      "3/3 - 0s - loss: 4859385.5000 - mae: 1581.3046 - val_loss: 10698768.0000 - val_mae: 2589.2932\n",
      "Epoch 310/350\n",
      "3/3 - 0s - loss: 5286065.0000 - mae: 1685.8491 - val_loss: 13411863.0000 - val_mae: 3023.5535\n",
      "Epoch 311/350\n",
      "3/3 - 0s - loss: 5648847.0000 - mae: 1872.0968 - val_loss: 10659479.0000 - val_mae: 2551.2112\n",
      "Epoch 312/350\n",
      "3/3 - 0s - loss: 5276632.0000 - mae: 1675.7944 - val_loss: 10539326.0000 - val_mae: 2572.0027\n",
      "Epoch 313/350\n",
      "3/3 - 0s - loss: 4760949.0000 - mae: 1567.8513 - val_loss: 13219581.0000 - val_mae: 3001.5989\n",
      "Epoch 314/350\n",
      "3/3 - 0s - loss: 5166867.5000 - mae: 1660.7805 - val_loss: 11142386.0000 - val_mae: 2679.7820\n",
      "Epoch 315/350\n",
      "3/3 - 0s - loss: 4926828.5000 - mae: 1621.6267 - val_loss: 11154468.0000 - val_mae: 2674.4094\n",
      "Epoch 316/350\n",
      "3/3 - 0s - loss: 5176050.0000 - mae: 1664.2479 - val_loss: 10843924.0000 - val_mae: 2628.2048\n",
      "Epoch 317/350\n",
      "3/3 - 0s - loss: 4999926.0000 - mae: 1623.0786 - val_loss: 12236195.0000 - val_mae: 2867.3713\n",
      "Epoch 318/350\n",
      "3/3 - 0s - loss: 5096725.0000 - mae: 1669.4995 - val_loss: 10416656.0000 - val_mae: 2548.5808\n",
      "Epoch 319/350\n",
      "3/3 - 0s - loss: 5267670.0000 - mae: 1665.4008 - val_loss: 12393981.0000 - val_mae: 2892.2878\n",
      "Epoch 320/350\n",
      "3/3 - 0s - loss: 4868583.5000 - mae: 1625.5625 - val_loss: 10557452.0000 - val_mae: 2535.8188\n",
      "Epoch 321/350\n",
      "3/3 - 0s - loss: 4885347.0000 - mae: 1657.7294 - val_loss: 13574140.0000 - val_mae: 3028.5830\n",
      "Epoch 322/350\n",
      "3/3 - 0s - loss: 5879961.5000 - mae: 1840.6689 - val_loss: 10571919.0000 - val_mae: 2561.5498\n",
      "Epoch 323/350\n",
      "3/3 - 0s - loss: 5246603.0000 - mae: 1660.7305 - val_loss: 10827859.0000 - val_mae: 2625.0884\n",
      "Epoch 324/350\n",
      "3/3 - 0s - loss: 5318006.0000 - mae: 1729.2280 - val_loss: 11943563.0000 - val_mae: 2835.8445\n",
      "Epoch 325/350\n",
      "3/3 - 0s - loss: 5633028.0000 - mae: 1747.0909 - val_loss: 10835239.0000 - val_mae: 2648.6455\n",
      "Epoch 326/350\n",
      "3/3 - 0s - loss: 4627414.0000 - mae: 1588.0039 - val_loss: 13199424.0000 - val_mae: 2974.6111\n",
      "Epoch 327/350\n",
      "3/3 - 0s - loss: 5039931.0000 - mae: 1663.1779 - val_loss: 10135831.0000 - val_mae: 2461.5764\n",
      "Epoch 328/350\n",
      "3/3 - 0s - loss: 5050308.0000 - mae: 1635.4954 - val_loss: 11102768.0000 - val_mae: 2671.7273\n",
      "Epoch 329/350\n",
      "3/3 - 0s - loss: 4830588.0000 - mae: 1593.8577 - val_loss: 12139099.0000 - val_mae: 2847.5889\n",
      "Epoch 330/350\n",
      "3/3 - 0s - loss: 4978980.0000 - mae: 1647.6266 - val_loss: 10742919.0000 - val_mae: 2604.7361\n",
      "Epoch 331/350\n",
      "3/3 - 0s - loss: 5031806.0000 - mae: 1625.6179 - val_loss: 11711816.0000 - val_mae: 2771.5369\n",
      "Epoch 332/350\n",
      "3/3 - 0s - loss: 4863991.0000 - mae: 1624.7926 - val_loss: 10268977.0000 - val_mae: 2484.3064\n",
      "Epoch 333/350\n",
      "3/3 - 0s - loss: 5011935.0000 - mae: 1639.6461 - val_loss: 12207059.0000 - val_mae: 2831.9973\n",
      "Epoch 334/350\n",
      "3/3 - 0s - loss: 4794786.5000 - mae: 1620.7424 - val_loss: 10348679.0000 - val_mae: 2491.9229\n",
      "Epoch 335/350\n",
      "3/3 - 0s - loss: 5406651.0000 - mae: 1717.9899 - val_loss: 11906963.0000 - val_mae: 2787.3069\n",
      "Epoch 336/350\n",
      "3/3 - 0s - loss: 5284829.0000 - mae: 1677.7710 - val_loss: 10772245.0000 - val_mae: 2601.6514\n",
      "Epoch 337/350\n",
      "3/3 - 0s - loss: 4845308.0000 - mae: 1612.4236 - val_loss: 10453733.0000 - val_mae: 2545.9578\n",
      "Epoch 338/350\n",
      "3/3 - 0s - loss: 4936209.0000 - mae: 1620.1591 - val_loss: 11686507.0000 - val_mae: 2783.8945\n",
      "Epoch 339/350\n",
      "3/3 - 0s - loss: 4694052.0000 - mae: 1565.0381 - val_loss: 10588331.0000 - val_mae: 2569.5803\n",
      "Epoch 340/350\n",
      "3/3 - 0s - loss: 4695192.0000 - mae: 1573.9735 - val_loss: 12364700.0000 - val_mae: 2866.5857\n",
      "Epoch 341/350\n",
      "3/3 - 0s - loss: 4872138.0000 - mae: 1643.8053 - val_loss: 10358808.0000 - val_mae: 2521.0100\n",
      "Epoch 342/350\n",
      "3/3 - 0s - loss: 5007714.5000 - mae: 1624.5503 - val_loss: 11187163.0000 - val_mae: 2687.8027\n",
      "Epoch 343/350\n",
      "3/3 - 0s - loss: 4898346.0000 - mae: 1643.8527 - val_loss: 12189615.0000 - val_mae: 2844.0579\n",
      "Epoch 344/350\n",
      "3/3 - 0s - loss: 4703444.5000 - mae: 1566.6978 - val_loss: 10321120.0000 - val_mae: 2513.2566\n",
      "Epoch 345/350\n",
      "3/3 - 0s - loss: 4761279.5000 - mae: 1602.0638 - val_loss: 11285805.0000 - val_mae: 2711.7422\n",
      "Epoch 346/350\n",
      "3/3 - 0s - loss: 4675975.0000 - mae: 1564.0520 - val_loss: 11533099.0000 - val_mae: 2742.0713\n",
      "Epoch 347/350\n",
      "3/3 - 0s - loss: 4596734.0000 - mae: 1543.3132 - val_loss: 10333849.0000 - val_mae: 2525.4873\n",
      "Epoch 348/350\n",
      "3/3 - 0s - loss: 4963331.0000 - mae: 1589.7833 - val_loss: 11264728.0000 - val_mae: 2710.8120\n",
      "Epoch 349/350\n",
      "3/3 - 0s - loss: 4672532.5000 - mae: 1577.1954 - val_loss: 10805811.0000 - val_mae: 2617.6169\n",
      "Epoch 350/350\n",
      "3/3 - 0s - loss: 4635985.0000 - mae: 1573.8362 - val_loss: 11905155.0000 - val_mae: 2797.6123\n",
      "MSE: 11905155.000, RMSE: 3450.385, MAE: 2797.612\n",
      "Predicted: 15133.745\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "from numpy import sqrt\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    " \n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return asarray(X), asarray(y)\n",
    " \n",
    "# load the dataset\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-car-sales.csv'\n",
    "df = read_csv(path, header=0, index_col=0, squeeze=True)\n",
    "\n",
    "# retrieve the values\n",
    "values = df.values.astype('float32')\n",
    "\n",
    "# specify the window size\n",
    "n_steps = 5\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(values, n_steps)\n",
    "\n",
    "# reshape into [samples, timesteps, features]\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# split into train/test\n",
    "n_test = 12\n",
    "X_train, X_test, y_train, y_test = X[:-n_test], X[-n_test:], y[:-n_test], y[-n_test:]\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_steps,1)))\n",
    "model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=350, batch_size=32, verbose=2, validation_data=(X_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "mse, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (mse, sqrt(mse), mae))\n",
    "\n",
    "# make a prediction\n",
    "row = asarray([18024.0, 16722.0, 14385.0, 21342.0, 17180.0]).reshape((1, n_steps, 1))\n",
    "yhat = model.predict(row)\n",
    "print('Predicted: %.3f' % (yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
